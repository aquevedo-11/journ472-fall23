---
title: "Graduate Student Assignment - JOUR772 Fall 2023"
author: "April Quevedo"
date: "2023-12-04"
output: html_document
---

### Project Directives

For this assignment, you will select one or more related datasets from Maryland's Open Data Portal.

Your task is to provide a profile of that data, describing its scope and limitations, checking for issues of standardization and errors, and exploring it to find potential story ideas.

You should explore the data to find at least 3 potential story ideas, and conduct enough analysis to describe the three best ideas you have in pitches. To do this, you should join it with one other source of information - that could be Census data or some other type of information that is related to the data you are working with.

Among the questions you should address are:

**Dataset Questions**

Who created and maintains the data? What state program or law is connected to it? What does each row represent? What is the chronological and geographic scope of this data? If this data contains aggregates (totals), can you find itemized data that those totals are derived from? Do the totals match your own calculations using the itemized data?

**Datset Question Answers**

The primary dataset for this project, Maryland Port Administration General Cargo, was created and is maintained by the Maryland Department of Transportation (MDOT)'s Maryland Port Administration. The data is updated monthly and contains data from the past 25 years (1998 to 2023). Each row represents the monthly amount of cargo volumes received in a category (according to column title). All information pertains to inbound and outbound cargo freight handled by the Port of Baltimore located in Baltimore, MD. Itemized data is not immediately available.

**Dataset techniques** I want you to demonstrate multiple techniques you've learned in this class, including: Generating summary data from itemized data using group_by and summarize. Cleaning up data as necessary. Describing in text the results of your work, your questions and potential story ideas. Visualizing data through at least two (2) charts and maps.

You will do this exploration and analysis in an R Markdown notebook that you create and put in your major assignments folder. Your notebook should be free of errors and I should be able to run the code in it from start to finish. The data you use should be included in your repository unless it is more than 50MB in size, in which case you can place it in a separate location that you give me access to (for example, Google Drive).

Your notebook should contain ample narrative of the decisions and choices you made in your work, including paths that didn't pan out. You should identify the most promising story ideas that your exploration has created and why they stand out, and you also should identify and describe questions that you may not have been able to answer but are worth exploring.

This assignment will be worth the equivalent of three labs. It will be due on Dec. 4 (so you have approximately one month).

### Background

For my project, I'd like to explore the Maryland Port Administration's monthly general cargo data. Most imports to the U.S. come through western ports - the largest being the Port of Los Angeles. West coast ports were overwhelmed during the pandemic, resulting in a shortage of available containers as well as cargo ships. The Port of Baltimore does not see the same volume as Los Angeles, nor is it a top five port on the east coast. However, with west coast ports being overwhelmed during the pandemic, transportation companies often rerouted ships to other ports in hopes of getting freight to their final destination quicker while also freeing up equipment. Using the linked dataset, I'd like to analyze total volumes entering the Port of Baltimore throughout the pandemic (2020-2021) in comparison to pre-pandemic (2018-2019) and post-pandemic (2022) volumes. Additionally, I'd like to locate and analyze data of the two largest neighboring ports (Port of Virginia and Port of New York/New Jersey).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation
options(scipen=999)
```

```{r}
library(tidyverse)
library(lubridate)
library(janitor)
library(ggplot2)
```

```{r}
port_of_bmore <- read_csv("data/baltimore_port_cargo_1998_2023.csv") |> clean_names()
port_of_nynj <- read_csv("data/port_of_nynj_2018_2022.csv") |> clean_names()
port_of_va <- read_csv("data/port_of_virginia_statistics_TEU.csv") |> clean_names()
US_ports_data <- read_csv("data/US_Port_Data_Export.csv") |> clean_names()
```

## Establishing baseline

To make sure I'm analyzing the data in each port file correctly, I located a file from the USDOT's data available on data.gov. The most complete year was 2019 (right before the pandemic). Below is code for the numbers reported to the USDOT.

```{r}
US_ports_data_big_3 <- US_ports_data |>
  filter(clean_port_name == "NY-NJ" | clean_port_name == "Baltimore" | clean_port_name == "Virginia") |>
  filter(reporting_year == 2019) |>
  filter(units == "Container TEUs") |>
  filter(trade_type == "TOTAL") |>
  select(clean_port_name, trade_type, reporting_year, volume)

US_ports_data_big_3 |>
  ggplot() +
  geom_bar(aes(x=clean_port_name, weight=volume)) +
  labs(
    title="Atlantic Coast Ports TEU Volumes in 2019",
    x = "Port",
    y = "Total TEUs",
    caption = "source: USDOT")

```

## Analyzing the Port of New York/New Jersey

The port of New York/New Jersey is the busiest of all ports located along the Atlantic Coast. With multiple airports, terminals/warehouses, and an extensive rail network, the Port of NY/NJ is best equipped to handle large volumes of import and export freight. In 2022, it became the second busiest port in the country, surpassing the Port of Long Beach.

Note: The original dataset I downloaded from the Port of NY/NJ's site contained freight volumes from 2000-2015. I know scraping from a site is possible but decided to manually create the set analyzed for years 2019-2022 in order to save some time.

```{r}
port_of_nynj_gg <- port_of_nynj |>
  filter(category == "Total TEUs") |> 
  pivot_longer(cols = -category, names_to = "year", values_to = "value")
#  pivot_longer(cols=c'Total TEUs', 'Category', names_to='Category', values_to = "Total TEUs")

port_of_nynj_gg |>
  ggplot() +
  geom_bar(aes(x=year, weight=value)) +
  labs(
    title="Annual Port of New York-New Jersey TEU Volumes 2019-2022",
    x = "Year",
    y = "Total TEUs",
    caption = "source: Port Authority of New York and New Jersey")

```

## Analyzing the Port of Virginia

Description of situation in VA goes here.

Note: The original dataset downloaded from the Port of Virginia's site was a .xlsx format. I converted to .csv and reloaded.

```{r}
port_of_va_gg <- port_of_va |> rename(count_type = x1) |> rename(load_type = x2) |>
  select(count_type, load_type, x2018, x2019, x2020, x2021, x2022) |>
  filter(count_type == "Total") |> filter(load_type == "Total TEUs")  |>
  #pivot_longer(cols = -count_type, names_to = "year", values_to = "value")
  pivot_longer(cols = -c(count_type, load_type), names_to = "year", values_to = "value")

port_of_va_gg |>
  ggplot() +
  geom_bar(aes(x=year, weight=value)) +
  labs(
    title="Annual Port of Virginia TEU Volumes 2019-2022",
    x = "Year",
    y = "Total TEUs",
    caption = "source: Port of Virginia")

```

## Analyzing the Port of Baltimore

Description of situation in Balty goes here.

```{r}
port_of_bmore_gg <- port_of_bmore |>
  mutate(month = my(month)) |>
  rename(date = month) |>
  mutate(year = format(as.Date(date), "%Y")) |>
  select(year, total_loaded_te_us) |>
  filter(year == "2018" | year == "2019" | year == "2020" | year == "2021" | year == "2022") |>
  group_by(year) |>
  summarise(sum_year = sum(total_loaded_te_us))

port_of_bmore_gg |>
  ggplot() +
  geom_bar(aes(x=year, weight=sum_year)) +
  labs(
    title="Annual Port of Baltimore TEU Volumes 2019-2022",
    x = "Year",
    y = "Total TEUs",
    caption = "source: Maryland Port Administration")

```
